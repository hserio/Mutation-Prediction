About the sklearn modules we are using 

Partial Fit method
"external memory" learning technique for a large input data
1) stream instances (examples)
- reading in instances from the data
2) Feature Extraction
- The sklearn.feature_extraction module can be used to extract features from datasets consisting of formats such as text and image
- DictVectorizer is also a useful representation transformation for training sequence classifiers in Natural Language Processing models that typically work by extracting feature windows around a particular word of interest
- statefull vs stateless vectorizer, if needed
- hashing trick for large categorixal data
3) Increment algorithm
- all algorithms cannot learn incrementally (without seeing all data at once), all estimators are valid options
- learn incrementakky from a mini bash of data which guarantees that at any given moment there is only a stated amount of instances in the main memory
- examples: classification, regression, clustering, decomposition (feature extraction)

Ref: https://scikit-learn.org/0.15/modules/scaling_strategies.html 
